{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import,division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from tensorflow.python.tpu import feature_column_v2 as fc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETTING LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength','SepalWidth','PetalLength','PetalWidth','Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING DATA FROM CSV WITH MODIFIED COLUMN NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
      "0          6.4         2.8          5.6         2.2        2\n",
      "1          5.0         2.3          3.3         1.0        1\n",
      "2          4.9         2.5          4.5         1.7        2\n",
      "3          4.9         3.1          1.5         0.1        0\n",
      "4          5.7         3.8          1.7         0.3        0\n",
      "\n",
      "    SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
      "0          5.9         3.0          4.2         1.5        1\n",
      "1          6.9         3.1          5.4         2.1        2\n",
      "2          5.1         3.3          1.7         0.5        0\n",
      "3          6.0         3.4          4.5         1.6        1\n",
      "4          5.5         2.5          4.0         1.3        1\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./datasets/iris_training.csv\",names=CSV_COLUMN_NAMES,header=0)\n",
    "test = pd.read_csv(\"./datasets/iris_test.csv\",names=CSV_COLUMN_NAMES,header=0)\n",
    "print(train.head())\n",
    "print(\"\\n\",test.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEPERATING THE SPECIES COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n",
      "\n",
      "    SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          5.9         3.0          4.2         1.5\n",
      "1          6.9         3.1          5.4         2.1\n",
      "2          5.1         3.3          1.7         0.5\n",
      "3          6.0         3.4          4.5         1.6\n",
      "4          5.5         2.5          4.0         1.3\n",
      "\n",
      " 0    2\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    0\n",
      "Name: Species, dtype: int64\n",
      "\n",
      " 0    1\n",
      "1    2\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: Species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_y=train.pop('Species')\n",
    "test_y=test.pop('Species')\n",
    "print(train.head())\n",
    "print(\"\\n\",test.head())\n",
    "print(\"\\n\",train_y.head())\n",
    "print(\"\\n\",test_y.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features,labels, training=True,batch_size=256):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE COLUMN ( Provides the column details to model along the unique data it can contain )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "my_feature_column = []\n",
    "for key in train.keys():\n",
    "    my_feature_column.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN CLASSIFIER ( Setting up the model structure )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADITYA\\AppData\\Local\\Temp\\tmp3ldg5zns\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADITYA\\\\AppData\\\\Local\\\\Temp\\\\tmp3ldg5zns', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_column,\n",
    "    hidden_units=[30,10],\n",
    "    n_classes=3\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADITYA\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\ADITYA\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adagrad.py:93: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ADITYA\\AppData\\Local\\Temp\\tmp3ldg5zns\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.6434798, step = 0\n",
      "INFO:tensorflow:global_step/sec: 663.838\n",
      "INFO:tensorflow:loss = 1.2009974, step = 100 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 1028.89\n",
      "INFO:tensorflow:loss = 1.0639919, step = 200 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1107.9\n",
      "INFO:tensorflow:loss = 0.98616093, step = 300 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 977.803\n",
      "INFO:tensorflow:loss = 0.95110077, step = 400 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1142.46\n",
      "INFO:tensorflow:loss = 0.93544817, step = 500 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1179.08\n",
      "INFO:tensorflow:loss = 0.9240782, step = 600 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1057.68\n",
      "INFO:tensorflow:loss = 0.9179101, step = 700 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1057.38\n",
      "INFO:tensorflow:loss = 0.9051585, step = 800 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1070.45\n",
      "INFO:tensorflow:loss = 0.89706403, step = 900 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1022.96\n",
      "INFO:tensorflow:loss = 0.90098333, step = 1000 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1097.96\n",
      "INFO:tensorflow:loss = 0.8869557, step = 1100 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1080.76\n",
      "INFO:tensorflow:loss = 0.87262774, step = 1200 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1192.41\n",
      "INFO:tensorflow:loss = 0.8731326, step = 1300 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1132.75\n",
      "INFO:tensorflow:loss = 0.86704934, step = 1400 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 996.357\n",
      "INFO:tensorflow:loss = 0.8626244, step = 1500 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1016.01\n",
      "INFO:tensorflow:loss = 0.85139513, step = 1600 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1108.77\n",
      "INFO:tensorflow:loss = 0.8522413, step = 1700 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 982.629\n",
      "INFO:tensorflow:loss = 0.84917164, step = 1800 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.931\n",
      "INFO:tensorflow:loss = 0.85864276, step = 1900 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1024.78\n",
      "INFO:tensorflow:loss = 0.8466285, step = 2000 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1193.27\n",
      "INFO:tensorflow:loss = 0.8354285, step = 2100 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1265.5\n",
      "INFO:tensorflow:loss = 0.83829415, step = 2200 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1308.16\n",
      "INFO:tensorflow:loss = 0.833172, step = 2300 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1189.83\n",
      "INFO:tensorflow:loss = 0.81988746, step = 2400 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1232.29\n",
      "INFO:tensorflow:loss = 0.8247577, step = 2500 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.64\n",
      "INFO:tensorflow:loss = 0.8255796, step = 2600 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.029\n",
      "INFO:tensorflow:loss = 0.81267005, step = 2700 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 1065.13\n",
      "INFO:tensorflow:loss = 0.81816995, step = 2800 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.821\n",
      "INFO:tensorflow:loss = 0.8048678, step = 2900 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1128.51\n",
      "INFO:tensorflow:loss = 0.799371, step = 3000 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1069.2\n",
      "INFO:tensorflow:loss = 0.81596076, step = 3100 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1069.37\n",
      "INFO:tensorflow:loss = 0.7964839, step = 3200 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1170.24\n",
      "INFO:tensorflow:loss = 0.7950934, step = 3300 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1123.83\n",
      "INFO:tensorflow:loss = 0.8019688, step = 3400 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1011.61\n",
      "INFO:tensorflow:loss = 0.7909057, step = 3500 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 971.567\n",
      "INFO:tensorflow:loss = 0.78994715, step = 3600 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1100.49\n",
      "INFO:tensorflow:loss = 0.78298664, step = 3700 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1070.4\n",
      "INFO:tensorflow:loss = 0.7914276, step = 3800 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1024.17\n",
      "INFO:tensorflow:loss = 0.7805158, step = 3900 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1078.38\n",
      "INFO:tensorflow:loss = 0.78544223, step = 4000 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1092.48\n",
      "INFO:tensorflow:loss = 0.78690827, step = 4100 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1113.81\n",
      "INFO:tensorflow:loss = 0.773018, step = 4200 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1072.33\n",
      "INFO:tensorflow:loss = 0.7734548, step = 4300 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1057.07\n",
      "INFO:tensorflow:loss = 0.761465, step = 4400 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1018.25\n",
      "INFO:tensorflow:loss = 0.76780105, step = 4500 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1018.18\n",
      "INFO:tensorflow:loss = 0.7735715, step = 4600 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1068.18\n",
      "INFO:tensorflow:loss = 0.7702277, step = 4700 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1097.68\n",
      "INFO:tensorflow:loss = 0.7635327, step = 4800 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1043.2\n",
      "INFO:tensorflow:loss = 0.7630013, step = 4900 (0.095 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\ADITYA\\AppData\\Local\\Temp\\tmp3ldg5zns\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.7651464.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x253e9c2a8f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train,train_y,training=True),\n",
    "    steps=5000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING IT ON A TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-05T21:17:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ADITYA\\AppData\\Local\\Temp\\tmp3ldg5zns\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.19618s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-05-21:17:04\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.46666667, average_loss = 0.79269814, global_step = 5000, loss = 0.79269814\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\ADITYA\\AppData\\Local\\Temp\\tmp3ldg5zns\\model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test,test_y,training=False)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRINTING ACCURACY OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy:  46.666666865348816\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set accuracy: ',(eval_result['accuracy']*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT FUNCTION FOR CUSTOM USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDING LABELS AND PREDICTION SET ( which contains the probabilities of the input being any one of the flower species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['SepalLength','SepalWidth','PetalLength','PetalWidth']\n",
    "predict={}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT THE CUSTON USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted: \n"
     ]
    }
   ],
   "source": [
    "print(\"Please type numeric values as prompted: \")\n",
    "for feature in features:\n",
    "    valid=True\n",
    "    while valid:\n",
    "        val = input(feature + \": \")\n",
    "        if not val.isdigit(): valid = False\n",
    "    predict[feature] = [float(val)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTING THE FLOWER SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISPLAY THE MAX PROBABILITY LABEL ( Species )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ADITYA\\AppData\\Local\\Temp\\tmp3ldg5zns\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Virginica\" (89.5%)\n"
     ]
    }
   ],
   "source": [
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id],100*probability\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
